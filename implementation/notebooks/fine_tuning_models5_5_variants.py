# -*- coding: utf-8 -*-
"""Copy of fine_tuning_models_3_variants_2-final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N32AnbktFZ2tIXC1LjKkW-y0lPzolVpD
"""

from google.colab import drive
drive.mount('/content/drive')
import os

import tables
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from scipy.fftpack import idst, dst
import cv2
import tensorflow as tf
from tensorflow.keras import Model
from tensorflow import keras
from tensorflow.keras.layers import *
import datetime
import shutil
import sys
import os
import json

from tensorflow.keras.layers import Conv2D
from tensorflow.keras.callbacks import Callback
from tensorflow.keras import losses

# batch_size=16
# lr_init = 5e-3
# # activation=4
# preload_data=True
# local=sys.platform=='win32'
# num_samples = -1 # use all samples
# num_epochs=50
# if local and preload_data: # override for small local experiments
#     num_samples=160
# if not local:  # override for long runs on the cloud
#     num_epochs=5000

def conv_params_hint_str(model,cfg):
    _=build_weights_from_cfg(model,cfg)
    n = model.count_params()       # count (trainable+non-trainable)
    return f"~{n:,}"

def summarize_run(name, model, cfg, df_metrics):
    PSNR_mean = df_metrics["PSNR"].mean()
    PSNR_std  = df_metrics["PSNR"].std()
    SSIM_mean = df_metrics["SSIM"].mean()
    SSIM_std  = df_metrics["SSIM"].std()
    MSE_mean  = df_metrics["MSE"].mean()
    MSE_std   = df_metrics["MSE"].std()

    entry = {
        "Params (approx)": conv_params_hint_str(model, cfg),
        "PSNRâ†‘": round(PSNR_mean, 3),
        "PSNR_std": round(PSNR_std, 3),
        "SSIMâ†‘": round(SSIM_mean, 4),
        "SSIM_std": round(SSIM_std, 4),
        "MSEâ†“": round(MSE_mean, 6),
        "MSE_std": round(MSE_std, 6),
    }

    # ×¤×©×•×˜ ×©×•××¨ ×ª×—×ª ×”×©× ×›-key
    RUN_SUMMARY[name] = entry

# --- Utility: dirs, paths, run names ---

def get_data_path(cfg):
    return os.path.join(cfg["library_path"], cfg["data_filename"])

def get_checkpoint_path(cfg):
    return os.path.join(cfg["weights_dir"], cfg["weights_filename"])

def ensure_dirs(cfg):
    os.makedirs(cfg["weights_dir"], exist_ok=True)
    os.makedirs(cfg["results_dir"], exist_ok=True)
    os.makedirs(cfg["logs_dir"], exist_ok=True)

def timestamp():
    return datetime.datetime.now().strftime("%Y%m%d-%H%M%S")

def prepare_paths(cfg):
    run_tag = f'{cfg["experiment_name"]}_{timestamp()}'
    log_dir = os.path.join(cfg["logs_dir"], run_tag)

    results_dir = os.path.join(cfg["results_dir"], cfg["experiment_name"])
    os.makedirs(results_dir, exist_ok=True)

    weights_dir = os.path.join(cfg["weights_dir"], cfg["experiment_name"])
    os.makedirs(weights_dir, exist_ok=True)

    checkpoint_path = os.path.join(weights_dir, cfg["weights_filename"])

    img_prefix = os.path.join(results_dir, cfg["experiment_name"])

    return log_dir, img_prefix, checkpoint_path

# Ref: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly
preload_data=True

import math

class DataGenerator(keras.utils.Sequence):
    def __init__(self, filename, all_inds, batch_size=32, shuffle=True, max_samples=None, **kwargs):
        super().__init__(**kwargs)
        self.batch_size = batch_size

        if (max_samples is not None) and (max_samples > 0):
            self.indexes = all_inds[:max_samples].astype(np.int32)
        else:
            self.indexes = all_inds.copy().astype(np.int32)

        self.h5_file = tables.open_file(filename, 'r')
        self.event_data_set = self.h5_file.root.train
        self.shuffle = shuffle
        self.on_epoch_end()
        if preload_data:
            self.X, self.y = self.event_data_set.images[self.indexes,...], self.event_data_set.laplacian[self.indexes,...]
            self.indexes = np.arange(self.indexes.shape[0])

    def __len__(self):
        # Denotes the number of batches per epoch
        return math.ceil(self.indexes.shape[0] / self.batch_size)

    def __getitem__(self, index):
        # Generate one batch of data
        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]

        # Generate data
        if preload_data:
            X,y = self.X[indexes], self.y[indexes]
        else:
            X, y = self.event_data_set.images[indexes,...], self.event_data_set.laplacian[indexes,...]
        return X, y

    def on_epoch_end(self):
        if self.shuffle == True:
            np.random.shuffle(self.indexes)

    def __del__(self):
        self.h5_file.close()

# np.random.seed(0); tf.random.set_seed(0)

# train = DataGenerator(data_path, inds[:int(num_train)], batch_size)
# val = DataGenerator(data_path, inds[int(num_train):int(num_train)+int(num_val)], batch_size)
# test = DataGenerator(data_path, inds[-int(num_test):], batch_size)

import tensorflow as tf
import numpy as np
from tensorflow.keras.callbacks import Callback
from tensorflow.python.keras import backend as K

# adapted from ReduceLROnPlateau
class RelativeReduceLROnPlateau(Callback):
    def __init__(self,
                 monitor='val_loss',
                 factor=0.1,
                 patience=10,
                 verbose=0,
                 alpha=0.01,
                 cooldown=0,
                 min_lr=0,
                 **kwargs):
        super(RelativeReduceLROnPlateau, self).__init__()

        self.monitor = monitor
        if factor >= 1.0:
            raise ValueError('RelativeReduceLROnPlateau ' 'does not support a factor >= 1.0.')
        self.factor = factor
        self.min_lr = min_lr
        self.alpha = alpha
        self.patience = patience
        self.verbose = verbose
        self.cooldown = cooldown
        self.cooldown_counter = 0  # Cooldown counter.
        self.wait = 0
        self.best = 0
        self.monitor_op = None
        self.mode = 'min'
        self._reset()

    def _reset(self):
        """Resets wait counter and cooldown counter.
        """
        if (self.mode == 'min' or
                (self.mode == 'auto' and 'acc' not in self.monitor)):
            self.monitor_op = lambda a, b: np.less(a, b*(1.-self.alpha))
            self.best = np.inf
        else:
            raise Exception('Not implemented')
        self.cooldown_counter = 0
        self.wait = 0

    def on_train_begin(self, logs=None):
        self._reset()

    def on_epoch_end(self, epoch, logs=None):
        logs = logs or {}
        logs['lr'] = K.get_value(self.model.optimizer.lr)
        current = logs.get(self.monitor)
        if current is None:
            pass
        else:
            if self.in_cooldown():
                self.cooldown_counter -= 1
                self.wait = 0

            if self.monitor_op(current, self.best):
                self.best = current
                self.wait = 0
            elif not self.in_cooldown():
                self.wait += 1
                if self.wait >= self.patience:
                    old_lr = float(K.get_value(self.model.optimizer.lr))
                    if old_lr > self.min_lr:
                        new_lr = old_lr*self.factor
                        new_lr = max(new_lr, self.min_lr)
                        K.set_value(self.model.optimizer.lr, new_lr)
                        if self.verbose > 0:
                            print('\nEpoch %05d: RelativeReduceLROnPlateau reducing learning '
                                  'rate to %s.'%(epoch+1, new_lr))
                        self.cooldown_counter = self.cooldown
                        self.wait = 0

    def in_cooldown(self):
        return self.cooldown_counter > 0

# adapted from EarlyStopping
class RelativeEarlyStopping(Callback):
  def __init__(self,
               monitor='val_loss',
               alpha=0.0,
               patience=0,
               earliest_epoch=0,
               verbose=0):
    super(RelativeEarlyStopping, self).__init__()
    self.monitor = monitor
    self.patience = patience
    self.verbose = verbose
    self.alpha = abs(alpha)
    self.wait = 0
    self.stopped_epoch = 0
    self.earliest_epcoh=earliest_epoch
    self.monitor_op = lambda a, b: np.less(a, b*(1.-self.alpha))


  def on_train_begin(self, logs=None):
    # Allow instances to be re-used
    self.wait = 0
    self.stopped_epoch = 0
    self.best = np.inf

  def on_epoch_end(self, epoch, logs=None):
    current = self.get_monitor_value(logs)
    if current is None:
      return
    if self.monitor_op(current, self.best):
      self.best = current
      self.wait = 0
    else:
      self.wait += 1
      if epoch>=self.earliest_epcoh and self.wait >= self.patience:
        self.stopped_epoch = epoch
        self.model.stop_training = True

  def on_train_end(self, logs=None):
    if self.stopped_epoch > 0 and self.verbose > 0:
      print('Epoch %05d: early stopping' % (self.stopped_epoch + 1))

  def get_monitor_value(self, logs):
    logs = logs or {}
    monitor_value = logs.get(self.monitor)
    return monitor_value

class EarlyStoppingWMinEpoch(Callback):
  def __init__(self,
               monitor='val_loss',
               min_delta=0,
               patience=0,
               verbose=0,
               mode='auto',
               baseline=None,
               restore_best_weights=False,
               earliest_epoch=0):
    super(EarlyStoppingWMinEpoch, self).__init__()

    self.monitor = monitor
    self.patience = patience
    self.verbose = verbose
    self.baseline = baseline
    self.min_delta = abs(min_delta)
    self.wait = 0
    self.stopped_epoch = 0
    self.restore_best_weights = restore_best_weights
    self.best_weights = None
    self.earliest_epoch = earliest_epoch

    if mode not in ['auto', 'min', 'max']:
      mode = 'auto'

    if mode == 'min':
      self.monitor_op = np.less
    elif mode == 'max':
      self.monitor_op = np.greater
    else:
      if 'acc' in self.monitor:
        self.monitor_op = np.greater
      else:
        self.monitor_op = np.less

    if self.monitor_op == np.greater:
      self.min_delta *= 1
    else:
      self.min_delta *= -1

  def on_train_begin(self, logs=None):
    # Allow instances to be re-used
    self.wait = 0
    self.stopped_epoch = 0
    if self.baseline is not None:
      self.best = self.baseline
    else:
      self.best = np.inf if self.monitor_op == np.less else -np.inf
    self.best_weights = None

  def on_epoch_end(self, epoch, logs=None):
    current = self.get_monitor_value(logs)
    if current is None:
      return
    if self.monitor_op(current - self.min_delta, self.best):
      self.best = current
      self.wait = 0
      if self.restore_best_weights:
        self.best_weights = self.model.get_weights()
    else:
      self.wait += 1
      if epoch>=self.earliest_epoch and self.wait >= self.patience:
        self.stopped_epoch = epoch
        self.model.stop_training = True
        if self.restore_best_weights:
          if self.verbose > 0:
            print('Restoring model weights from the end of the best epoch.')
          self.model.set_weights(self.best_weights)

  def on_train_end(self, logs=None):
    if self.stopped_epoch > 0 and self.verbose > 0:
      print('Epoch %05d: early stopping' % (self.stopped_epoch + 1))

  def get_monitor_value(self, logs):
    logs = logs or {}
    monitor_value = logs.get(self.monitor)
    return monitor_value

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
import datetime, os
# %tensorboard --logdir logs

def swish(x):
    return tf.keras.activations.swish(x)

def mish(x):
    return x * tf.math.tanh(tf.math.softplus(x))

# ---------- 1. Activation Function Registry (Best Practice) ----------
# Use a dictionary to map names to functions for easy configuration.
activation_functions = {
    'lerelu': tf.nn.leaky_relu,
    'relu': tf.nn.relu,
    'tanh': tf.nn.tanh,
    'swish': swish,
    'mish': mish
}

activation_keys = list(activation_functions.keys())

# ---------- Helpers ----------
def denum_matrix(n_row: int, n_col: int) -> np.ndarray:
    """Eigenvalue denominator for the 2D Poisson solver."""
    x = np.arange(1, n_col + 1, dtype=np.float64)
    y = np.arange(1, n_row + 1, dtype=np.float64)
    xv, yv = np.meshgrid(x, y)
    lam_x = 2.0 * np.cos(np.pi * xv / (n_col + 1.0)) - 2.0
    lam_y = 2.0 * np.cos(np.pi * yv / (n_row + 1.0)) - 2.0
    den = lam_x + lam_y
    return den

def norm_image(x):
    """Safe [0,1] normalization per-sample."""
    x = tf.convert_to_tensor(x, dtype=tf.float32)
    reduce_axes = tf.range(tf.rank(x) - 3, tf.rank(x))
    x_min = tf.reduce_min(x, axis=reduce_axes, keepdims=True)
    x_max = tf.reduce_max(x, axis=reduce_axes, keepdims=True)
    return tf.math.divide_no_nan(x - x_min, x_max - x_min)

# ---------- Precompute matrices (Restored) ----------
h, w = (90, 120)
denum_mat = denum_matrix(h, w)
denum_mat_ei = 1.0 / denum_mat

# Orthonormal DST/IDST operators using SciPy
dst_mat_w = dst(np.eye(w), type=2, axis=0, norm='ortho')
dst_mat_h = dst(np.eye(h), type=2, axis=0, norm='ortho')
idst_mat_w = idst(np.eye(w), type=2, axis=0, norm='ortho')
idst_mat_h = idst(np.eye(h), type=2, axis=0, norm='ortho')

# TensorFlow constants (float32)
c_denum_mat_ei = tf.constant(denum_mat_ei, dtype=tf.float32)
c_dst_mat_w    = tf.constant(dst_mat_w,    dtype=tf.float32)
c_dst_mat_h    = tf.constant(dst_mat_h,    dtype=tf.float32)
c_idst_mat_w   = tf.constant(idst_mat_w,   dtype=tf.float32)
c_idst_mat_h   = tf.constant(idst_mat_h,   dtype=tf.float32)


# ---------- Solvers (Restored to tf.matmul implementation) ----------
@tf.function
def solve_poiss_tf(grad: tf.Tensor) -> tf.Tensor:
    """
    Poisson solver in TF using separable DST-II and pre-computed matrices.
    This version is robust and works across all TF backends.
    """
    # Check if the channel dimension exists (rank 4) and squeeze it.
    if grad.shape.rank == 4:
        grad = tf.squeeze(grad, axis=-1) # Shape becomes [B, H, W]

    # Now, grad is guaranteed to be shape [B, 90, 120]
    # Note: tf.matmul does batch matrix multiplication automatically.
    # For (B, H, W) @ (W, W) -> (B, H, W)
    # For (H, H) @ (B, H, W) -> This doesn't work directly, so we transpose.

    # DST along rows (axis=1)
    z = tf.matmul(c_dst_mat_h, grad)        # [90, 90] @ [B, 90, 120] -> [B, 90, 120]

    # DST along columns (axis=2) requires transpose
    z = tf.transpose(z, perm=[0, 2, 1])     # -> [B, 120, 90]
    z = tf.matmul(c_dst_mat_w, z)           # [120, 120] @ [B, 120, 90] -> [B, 120, 90]
    z = tf.transpose(z, perm=[0, 2, 1])     # -> [B, 90, 120]

    d = c_denum_mat_ei * z

    # IDST along rows (axis=1)
    res = tf.matmul(c_idst_mat_h, d)        # [90, 90] @ [B, 90, 120] -> [B, 90, 120]

    # IDST along columns (axis=2) requires transpose
    res = tf.transpose(res, perm=[0, 2, 1]) # -> [B, 120, 90]
    res = tf.matmul(c_idst_mat_w, res)      # [120, 120] @ [B, 120, 90] -> [B, 120, 90]
    res = tf.transpose(res, perm=[0, 2, 1]) # -> [B, 90, 120]

    return tf.expand_dims(res, axis=-1)      # Return shape [B, 90, 120, 1]

# ---------- Metrics and Loss Functions ----------
def esmr_mse(gt: tf.Tensor, pred: tf.Tensor) -> tf.Tensor:
    """Mean squared error as a scalar, robust to channel dimension mismatches."""
    gt = tf.cast(gt, tf.float32)
    pred = tf.cast(pred, tf.float32)

    # --- THIS IS THE FIX ---
    # If gt is [B, H, W] and pred is [B, H, W, 1], add the channel dim to gt.
    if gt.shape.rank < pred.shape.rank:
        gt = tf.expand_dims(gt, axis=-1)

    return tf.reduce_mean(tf.math.squared_difference(gt, pred))

def esmr_clip_ssim(gt: tf.Tensor, pred: tf.Tensor) -> tf.Tensor:
    """Reconstruct, normalize, and compute clipped SSIM."""
    rec_img = norm_image(solve_poiss_tf(pred))
    gt_img  = norm_image(solve_poiss_tf(gt))
    ssim = tf.image.ssim(gt_img, rec_img, max_val=1.0, filter_size=5)
    return tf.reduce_mean(tf.clip_by_value(ssim, 0.0, 1.0))

@tf.function
def get_edge_tf(img):
    """Calculates image gradients to find edges."""
    vert = img[:, 1:, :, :] - img[:, :-1, :, :]
    hor = img[:, :, 1:, :] - img[:, :, :-1, :]
    tot = tf.square(vert[:, :, :-1, :]) + tf.square(hor[:, :-1, :, :])
    return tot

def make_lapl_loss(lam1=1.0, lam2=0.25, lam3=0.25):
    def lapl_loss(gt, pred):
        """Custom loss, robust to channel dimension mismatches."""
        gt = tf.cast(gt, tf.float32)
        pred = tf.cast(pred, tf.float32)

        # --- THIS IS THE FIX (applied here as well) ---
        # Ensure shapes match before the MAE calculation and Poisson solver calls.
        if gt.shape.rank < pred.shape.rank:
            gt = tf.expand_dims(gt, axis=-1)

        rec_img = norm_image(solve_poiss_tf(pred))
        gt_img = norm_image(solve_poiss_tf(gt))

        rec_edges = get_edge_tf(rec_img)
        rec_edges = tf.clip_by_value(rec_edges * 40.0, 0.0, 1.0)

        gt_edges = get_edge_tf(gt_img)
        gt_edges = tf.cast(gt_edges * 40.0 > 1.0, tf.float32)

        ssim_loss = 1.0 - tf.reduce_mean(tf.clip_by_value(tf.image.ssim(gt_img, rec_img, max_val=1.0, filter_size=5), 0.0, 1.0))
        edge_segm_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(gt_edges, rec_edges))

        # This MAE calculation is now safe.
        mae_loss = tf.reduce_mean(tf.keras.losses.mae(gt, pred))

        return lam1*mae_loss + lam2 * ssim_loss + lam3 * edge_segm_loss
    return lapl_loss

# ---------- 2. Improved Callbacks ----------
class LearningRateLogger(Callback):
    """Logs the current learning rate to the logs dictionary."""
    def __init__(self):
        super().__init__()
        self._supports_tf_logs = True

    def on_epoch_end(self, epoch, logs=None):
        if logs is None:
            logs = {}
        # This robustly gets the LR, even with schedulers
        current_lr = self.model.optimizer.learning_rate
        if isinstance(current_lr, tf.keras.optimizers.schedules.LearningRateSchedule):
            current_lr = current_lr(self.model.optimizer.iterations)
        logs["learning_rate"] = current_lr

# All your custom callbacks (RelativeReduceLROnPlateau, etc.) are well-written.
# The main change is to avoid the deprecated Keras backend.
class RelativeReduceLROnPlateau(Callback):
    def __init__(self, monitor='val_loss', factor=0.1, patience=10, verbose=1,
                 alpha=0.01, cooldown=0, min_lr=0, **kwargs):
        super().__init__()
        self.monitor = monitor
        self.factor = factor
        self.min_lr = min_lr
        self.alpha = alpha
        self.patience = patience
        self.verbose = verbose
        self.cooldown = cooldown
        self.wait = 0
        self.best = np.inf
        self.cooldown_counter = 0
        self.monitor_op = lambda a, b: np.less(a, b * (1. - self.alpha))

    def on_train_begin(self, logs=None):
        self.wait = 0
        self.best = np.inf
        self.cooldown_counter = 0

    def on_epoch_end(self, epoch, logs=None):
        current = logs.get(self.monitor)
        if current is None:
            return

        if self.cooldown_counter > 0:
            self.cooldown_counter -= 1
            self.wait = 0

        if self.monitor_op(current, self.best):
            self.best = current
            self.wait = 0
        elif self.cooldown_counter <= 0:
            self.wait += 1
            if self.wait >= self.patience:
                # Use the public API to get and set learning rate
                old_lr = self.model.optimizer.learning_rate.numpy()
                if old_lr > self.min_lr:
                    new_lr = old_lr * self.factor
                    new_lr = max(new_lr, self.min_lr)
                    self.model.optimizer.learning_rate.assign(new_lr)
                    if self.verbose > 0:
                        print(f'\nEpoch {epoch + 1:05d}: RelativeReduceLROnPlateau reducing learning rate to {new_lr}.')
                    self.cooldown_counter = self.cooldown
                    self.wait = 0

class SharedWeightNet(Model):
    def __init__(self, name='SharedWeightNet', activation='mish', **kwargs):
        super(SharedWeightNet, self).__init__(**kwargs)

        # Get the activation function from its string name
        if activation == 'mish':
            self.activation_fn = mish   # assume mish is defined elsewhere
        else:
            self.activation_fn = tf.keras.activations.get(activation)

        self.c1_f = 2
        self.c0   = Conv2D(3, 3, padding='same', name="c0")
        self.c1   = Conv2D(self.c1_f, 1, padding='same', name="c1")
        self.c3   = Conv2D(3, 1, padding='valid', name="c3")
        self.c3_1 = Conv2D(3, 1, padding='valid', name="c3_1")
        self.c4   = Conv2D(1, 1, padding='valid', name="c4")

    # (Optional) implement build to avoid the warning when calling model.build(...)
    def build(self, input_shape):
        # Create variables by making a dummy forward pass
        dummy = tf.zeros([1] + list(input_shape[1:]))  # e.g. [1,90,120,6]
        _ = self.call(dummy)
        super().build(input_shape)

    # def call(self, x):
    def call(self, x, training=False):

        # x: [B, 90, 120, 6]
        x = tf.transpose(x, perm=[0, 3, 1, 2])            # [B, 6, 90, 120]
        x = tf.reshape(x, (-1, 90, 120, 1))               # [B*6, 90, 120, 1]
        x = self.activation_fn(self.c0(x))
        x = self.activation_fn(self.c1(x))
        x = tf.reshape(x, (-1, 6, 90, 120, self.c1_f))    # [B, 6, 90, 120, 2]
        x = tf.transpose(x, perm=[0, 2, 3, 1, 4])         # [B, 90, 120, 6, 2]
        x = tf.reshape(x, (-1, 90, 120, 6 * self.c1_f))   # [B, 90, 120, 12]
        x = self.activation_fn(self.c3(x))
        x = self.activation_fn(self.c3_1(x))
        return self.c4(x)

# norm_type in {"none","bn","ln","gn"}; requires tfa for "gn".
class StandardConvNetFlex(tf.keras.Model):
    def __init__(self, activation="relu", width=3, dilation_rate=1,
                 norm_type="none", gn_groups=4, **kwargs):
        super().__init__(**kwargs)

        if activation == 'mish':
            self.activation_fn = mish   # assume mish is defined elsewhere
        else:
            self.activation_fn = tf.keras.activations.get(activation)

        self.norm_type = norm_type
        self.gn_groups = gn_groups

        # define 4 conv blocks + final 1x1
        self.conv0 = Conv2D(width, 3, padding="same", dilation_rate=dilation_rate, activation=None, name="conv0")
        self.n0    = self._make_norm()
        self.conv1 = Conv2D(width, 3, padding="same", dilation_rate=dilation_rate, activation=None, name="conv1")
        self.n1    = self._make_norm()
        self.conv2 = Conv2D(width, 1, padding="same", activation=None, name="conv2")
        self.n2    = self._make_norm()
        self.conv3 = Conv2D(width, 1, padding="same", activation=None, name="conv3")
        self.n3    = self._make_norm()
        self.conv4 = Conv2D(1, 1, padding="same", name="conv4")

    def _make_norm(self):
        if self.norm_type == "bn":
            return tf.keras.layers.BatchNormalization()
        elif self.norm_type == "ln":
            return tf.keras.layers.LayerNormalization(axis=[1,2,3])
        elif self.norm_type == "gn":
            from tensorflow_addons.layers import GroupNormalization
            return GroupNormalization(groups=self.gn_groups, axis=-1)
        else:
            return None  # no norm

    def _apply_block(self, x, conv, norm, training):
        x = conv(x)
        if norm is not None:
            x = norm(x, training=training)
        return self.activation_fn(x)

    def call(self, x, training=False):
        x = self._apply_block(x, self.conv0, self.n0, training)
        x = self._apply_block(x, self.conv1, self.n1, training)
        x = self._apply_block(x, self.conv2, self.n2, training)
        x = self._apply_block(x, self.conv3, self.n3, training)
        return self.conv4(x)

    def get_config(self):
        # helpful if you save full model
        return {
            "activation": tf.keras.activations.serialize(self.activation_fn),
            "width": self.conv0.filters,
            "dilation_rate": self.conv0.dilation_rate,
            "norm_type": self.norm_type,
            "gn_groups": self.gn_groups,
            "name": self.name,
        }

def build_model_from_cfg(cfg):
    name   = cfg["model_name"]
    kwargs = dict(cfg.get("model_kwargs", {}))

    if name in ("standard", "standard_flex"):   # allow old alias "standard"
        return StandardConvNetFlex(**kwargs)
    elif name == "shared":
        return SharedWeightNet(**kwargs)
    else:
        raise ValueError(f"Unknown model_name: {name}")

def build_weights_from_cfg(model, cfg):
    return model(tf.random.uniform([1, 90, 120, 6]))

# model = build_model_from_cfg(CFG)
# build_weights_from_cfg(CFG)  # build weights
# model.summary()

# conv_params_hint_str(model,CFG)

# pred_lapl = tf.squeeze(model(batch[0]),-1)
# print(pred_lapl.shape)

import pandas as pd

# ================== Load Trained Weights & Evaluate on Test Set ==================

def evaluate_on_test(model, img_prefix, test, save=False) :

      # --- Metrics Containers ---
      psnr, ssim, mse = [], [], []                 # per-batch means
      psnr_img, ssim_img, mse_img = [], [], []     # per-image flat list

      # --- Inference Loop over Test Batches ---
      for i in range(len(test)):
          batch = test[i]
          laplacian = batch[1]

          # ---------- Ground-truth Reconstruction (from Laplacian) ----------
          gt_img = solve_poiss_tf(tf.constant(laplacian))
          gt_img = norm_image(gt_img).numpy()

          # ---------- Model Prediction: Laplacian â†’ Reconstruction ----------
          pred_lapl = tf.squeeze(model(batch[0]), -1)
          pred_img = solve_poiss_tf(pred_lapl)
          pred_img = norm_image(pred_img).numpy()

          # Save gt and predicted image (uint8)
          if save:
              gt_img_u8 = (gt_img[0, ..., 0] * 255.0).astype(np.uint8)  # (H,W) uint8
              cv2.imwrite(f"{img_prefix}_test{i:04d}_gt.png",   gt_img_u8)
              pred_img_u8 = (pred_img[0, ..., 0] * 255.0).astype(np.uint8)  # (H,W) uint8
              cv2.imwrite(f"{img_prefix}_test{i:04d}_pred.png", pred_img_u8)

          # ---------- Per-image vectors (length B) ----------
          psnr_b = tf.image.psnr(gt_img,  pred_img, max_val=1.0)                 # (B,)
          ssim_b = tf.image.ssim(gt_img,  pred_img, max_val=1.0, filter_size=5)  # (B,)
          mse_b  = tf.reduce_mean(tf.square(gt_img - pred_img), axis=[1, 2, 3])

          psnr_img.extend(psnr_b.numpy().tolist())
          ssim_img.extend(ssim_b.numpy().tolist())
          mse_img .extend(mse_b.numpy().tolist())

          # ---------- Per-sample Metrics ----------
          psnr.append(float(tf.reduce_mean(psnr_b).numpy()))
          ssim.append(float(tf.reduce_mean(ssim_b).numpy()))
          mse.append(float(tf.reduce_mean(mse_b).numpy()))

      # print(pred_img.shape)
      # print(gt_img.shape)
      # ================== Aggregate Metrics ==================
      print("Per-batch means:", np.mean(psnr), np.mean(ssim), np.mean(mse))
      print("Per-image means:",
            float(tf.reduce_mean(psnr_b).numpy()),
            float(tf.reduce_mean(ssim_b).numpy()),
            float(tf.reduce_mean(mse_b).numpy()),)

      # ================== Metrics DataFrame (PSNR / SSIM / MSE) ==================
      df = pd.DataFrame({"PSNR": psnr, "SSIM": ssim, "MSE": mse})
      df_img = pd.DataFrame({"PSNR": psnr_img, "SSIM": ssim_img, "MSE": mse_img})

      if save:
          csv_path = f"{img_prefix}_metrics.csv"
          df.to_csv(csv_path, index=False)
          print(f"Saved metrics CSV â†’ {csv_path}")
      return (df , df_img)

import matplotlib.pyplot as plt

def plot_metrics(df):

    psnr = df["PSNR"]
    ssim = df["SSIM"]
    mse  = df["MSE"]

    plt.figure(figsize=(15, 4))

    plt.subplot(1, 3, 1)
    plt.hist(psnr, bins=20, color='skyblue')
    plt.title('PSNR Distribution')
    plt.xlabel('PSNR (dB)')
    plt.ylabel('Count')

    plt.subplot(1, 3, 2)
    plt.hist(ssim, bins=20, color='lightgreen')
    plt.title('SSIM Distribution')
    plt.xlabel('SSIM')
    plt.ylabel('Count')

    plt.subplot(1, 3, 3)
    plt.hist(mse, bins=20, color='salmon')
    plt.title('MSE Distribution')
    plt.xlabel('MSE')
    plt.ylabel('Count')

    plt.tight_layout()
    plt.show()


    return

def run_experiment(CFG):

    global HISTORIES, EXP_PATHS, RUN_SUMMARY

    # --- ensure globals exist ---
    if "HISTORIES" not in globals(): HISTORIES = {}
    if "EXP_PATHS" not in globals(): EXP_PATHS = {}
    if "RUN_SUMMARY" not in globals(): RUN_SUMMARY = {}

    # --- Reproducibility ---
    np.random.seed(CFG.get("seed", 0))
    tf.random.set_seed(CFG.get("seed", 0))

    # --- Data generator ---
    data_path = get_data_path(CFG)
    with tables.open_file(data_path, 'r') as h5_file:
        data_len = h5_file.root.train.images.shape[0]

    inds = np.arange(data_len)
    np.random.shuffle(inds)
    num_val = max(1, round(data_len*0.15))
    num_test = num_val
    # num_train = data_len-num_val-num_test
    num_train = 500

    batch_size   = CFG["batch_size"]
    num_samples  = CFG["num_samples"]
    num_epochs   = CFG["num_epochs"]
    # preload_data = CFG["preload_data"]

    train = DataGenerator(data_path, inds[:num_train], batch_size, shuffle=True,  max_samples=num_samples if num_samples>0 else None)
    val   = DataGenerator(data_path, inds[num_train:num_train+num_val], batch_size, shuffle=False, max_samples=None)   # ×›×œ ×”-val
    test  = DataGenerator(data_path, inds[-num_test:], batch_size, shuffle=False, max_samples=None)                    # ×›×œ ×”-test

    globals()["test"] = test # expose test to evaluation funcs if they read it globally

    # --- User Control Flags ---
    upload_weights = CFG['upload_weights']
    file_base_name = CFG['file_base_name'] # This key *should* be present from update calls

    # --- Paths and Directories ---
    ensure_dirs(CFG)
    log_dir, img_prefix, checkpoint_path = prepare_paths(CFG)
    drive_weights_dir = CFG["library_path"]           # source in drive
    # checkpoint_path      # destinations weights_dir/weights_filename
    src_path = os.path.join(drive_weights_dir, CFG["weights_filename"])

    # --- Build the model ---
    model = build_model_from_cfg(CFG)
    build_weights_from_cfg(model,CFG)  # build weights
    model.summary()

    # --- Pretrained Weights Handling ---
    weight_path = None

    if upload_weights:
        # Copy pretrained weights from Drive into local working directory
        src_path = os.path.join(drive_weights_dir, f"{file_base_name}")
        if os.path.exists(src_path):
            dst_path = checkpoint_path
            shutil.copy(src_path, dst_path)
            weight_path = dst_path
            print(f"âœ… Copied pretrained weights from Drive: {src_path} â†’ {dst_path}")
        else:
            print(f"âš ï¸ No pretrained weights found at {src_path}. Training from scratch.")
    else:
        print("â„¹ï¸ Training from scratch. A new weights file will be created.")

    # Load weights if found
    if weight_path and os.path.isfile(weight_path):
        try:
            # model.load_weights(checkpoint_path ,by_name=True, skip_mismatch=True)
            model.load_weights(checkpoint_path)
            print(f"âœ… Loaded weights into model from: {weight_path}")
            # flag = 0
        except Exception as e:
            print(f"âš ï¸ Could not load weights: {e}")
            # flag = 1

    # --- Logging and Callbacks ---
    tensorboard_callback = tf.keras.callbacks.TensorBoard(
        log_dir=log_dir, update_freq='epoch', profile_batch=0
    )
    lr_callback = RelativeReduceLROnPlateau(
        monitor='val_loss', factor=0.8, patience=6, verbose=1,
        alpha=0.005, cooldown=0, min_lr=2e-6
    )

    chkpt = tf.keras.callbacks.ModelCheckpoint(
        filepath=checkpoint_path,
        monitor='val_esmr_clip_ssim',
        mode='max',
        save_best_only=True
    )

    early_stopping = EarlyStoppingWMinEpoch(
        monitor='val_esmr_clip_ssim',
        min_delta=0.005,
        mode='max',
        patience=20,
        earliest_epoch=150
    )

    callbacks = [tensorboard_callback, lr_callback, chkpt, early_stopping]

    # ================== Evaluate before training ==================
    # if flag == 1:
    #   if os.path.isfile(src_path):
    #       model.load_weights(src_path)
    #   metrics_before , metrics_before_img = evaluate_on_test(model,img_prefix)

    # --- Train ---
    lamdas = CFG.get("loss_lambdas", {"l1":1.0, "l2":0.25, "l3":0.25})
    loss_fn = make_lapl_loss(lamdas["l1"], lamdas["l2"], lamdas["l3"])

    opt = tf.keras.optimizers.Adam(learning_rate=CFG["lr_init"])
    model.compile( optimizer=opt, loss=loss_fn, metrics=[esmr_mse, esmr_clip_ssim])
    history = model.fit(train, validation_data=val, epochs=num_epochs,
                      callbacks = [tensorboard_callback, lr_callback, chkpt, early_stopping])

    #  --- Save config file ---
    cfg_path = os.path.join(CFG["results_dir"], f"{CFG['experiment_name']}_config.json")
    with open(cfg_path, "w") as f:
        json.dump(CFG, f, indent=2)
    print(f"âœ… Saved config: {cfg_path}")

    # --- Save History ---
    HISTORIES[CFG["experiment_name"]] = history.history

    # --- Best Model Evaluation ---
    if os.path.isfile(checkpoint_path):
        model.load_weights(checkpoint_path)
        print(f"âœ… Reloaded best checkpoint: {checkpoint_path}")
    metrics_after_batch , metrics_after_img= evaluate_on_test(model,img_prefix,test,True)


    # --- Paths dictionary ---
    paths = {
        "experiment": CFG["experiment_name"],
        "src_path": src_path,
        "checkpoint_path": checkpoint_path,
        "img_prefix": img_prefix,
        "log_dir": log_dir,
        "results_dir": CFG["results_dir"],
        "weights_dir": CFG["weights_dir"],
        "metrics_csv": f"{img_prefix}_metrics.csv",
        # "preview_images": preview_files  # list of saved GT/PRED preview PNGs
    }

    # --- Update global dictionary ---
    EXP_PATHS[CFG["experiment_name"]] = paths

    # --- save  summary ---
    summarize_run(CFG["experiment_name"], model, CFG,  metrics_after_img)


    # --- auto-backup results + weights ---

    return model, metrics_after_batch, metrics_after_img

import shutil, os

def backup_all_results(backup_root):
    import datetime
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    exp_dir = os.path.join(backup_root, f"backup_{timestamp}")
    os.makedirs(exp_dir, exist_ok=True)

    try:
        # copy results
        if os.path.exists("./results"):
            dst_results = os.path.join(exp_dir, "results")
            shutil.copytree("./results", dst_results)
            print(f"âœ… Copied results â†’ {dst_results}")
        else:
            print("âš ï¸ No ./results folder found.")

        # copy trained_models
        if os.path.exists("./trained_models"):
            dst_models = os.path.join(exp_dir, "trained_models")
            shutil.copytree("./trained_models", dst_models)
            print(f"âœ… Copied trained_models â†’ {dst_models}")
        else:
            print("âš ï¸ No ./trained_models folder found.")

    except Exception as e:
        print(f"âš ï¸ Backup failed: {e}")

BASE = {
    "seed": 0,
    "upload_weights": True,
    "preload_data": True,
    "weights_policy": "load_if_exists",
    "weights_dir": "./trained_models",
    "results_dir": "./results", # images + CSV
    "logs_dir": "./logs", # TensorBoard
    "use_drive": True, # set False if running locally without Google Drive
    "drive_mount_point": "/content/drive",
    "library_path": "/content/drive/MyDrive/OpenU/Hadar cohen - Nbel-lab/Seminar in cs 2025/exercise/CVPR-2021-W",
    "data_filename": "caltech101_events_acc_90_120_6_var_1.hdf5",
    "backup_root": "/content/drive/MyDrive/OpenU/Hadar cohen - Nbel-lab/Seminar in cs 2025/exercise/work in progress",
}

# # Baseline (no norm, no dilation)
# "model_name": "standard",
# "model_kwargs": {"activation": "relu", "width": 3, "norm_type": "none", "dilation_rate": 1}

# # LayerNorm
# "model_kwargs": {"activation": "relu", "width": 3, "norm_type": "ln"}

# # GroupNorm (width=3 â‡’ groups must be 1 or 3)
# "model_kwargs": {"activation": "relu", "width": 3, "norm_type": "gn", "gn_groups": 3}

# # Dilated + BN
# "model_kwargs": {"activation": "relu", "width": 3, "norm_type": "bn", "dilation_rate": 2}

VARIANTS = [
    {
        "experiment_name": "v1_baseline",
        "exp_titles":"ReLU",
        "model_name": "standard",
        "model_kwargs": {"activation": "relu", "width": 3, "norm_type": "none", "dilation_rate": 1},
        "upload_weights": True,
        "file_base_name": "best_model_simplet_6_fixed_model5.h5", # StandardConvNet
        "weights_filename": "v1_baseline_best_model.h5", # StandardConvNet
        "loss_lambdas": {"l1":1.0, "l2":0.25, "l3":0.25},
        "num_samples": 150, # -1 = use all samples; small number for quick runs
        "lr_init": 1e-6,
        "num_epochs": 10,
        "batch_size": 16,
        "preload_data": True,

    },
    {
        "experiment_name": "v2_mish",
        "exp_titles":"Mish",
        "model_name": "standard",
        "model_kwargs": {"activation": "mish", "width": 3, "norm_type": "none", "dilation_rate": 1},
        "upload_weights": True,
        "file_base_name": "best_model_simplet_6_fixed_model5.h5", # StandardConvNet
        "weights_filename": "v2_mish_best_model.h5", # StandardConvNet
        "loss_lambdas": {"l1":1.0, "l2":0.25, "l3":0.25},
        "num_samples": 150, # -1 = use all samples; small number for quick runs
        "lr_init": 5e-4,
        "num_epochs": 30,
        "batch_size": 16,
        "preload_data": True,
    },
    {
        "experiment_name": "v3_SSIM_emphasized",
        "exp_titles":"SSIM",
        "model_name": "standard",
        "model_kwargs": {"activation": "relu", "width": 3, "norm_type": "none", "dilation_rate": 1},
        "upload_weights": True,
        "file_base_name": "best_model_simplet_6_fixed_model5.h5", # StandardConvNet
        "weights_filename": "v3_SSIM_emphasized_best_model.h5", # StandardConvNet
        "loss_lambdas": {"l1":1.0, "l2":0.35, "l3":0.15},
        "num_samples": 150, # -1 = use all samples; small number for quick runs
        "lr_init": 5e-4,
        "num_epochs": 50,
        "batch_size": 16,
        "preload_data": True,
    },
    {
        "experiment_name": "v4_Edge_emphasized",
        "exp_titles":"Edge",
        "model_name": "standard",
        "model_kwargs": {"activation": "relu", "width": 3, "norm_type": "none", "dilation_rate": 1},
        "upload_weights": True,
        "file_base_name": "best_model_simplet_6_fixed_model5.h5", # StandardConvNet
        "weights_filename": "v4_Edge_emphasized_best_model.h5", # StandardConvNet
        "loss_lambdas": {"l1":1.0, "l2":0.15, "l3":0.35},
        "num_samples": 150, # -1 = use all samples; small number for quick runs
        "lr_init": 5e-4,
        "num_epochs": 50,
        "batch_size": 16,
        "preload_data": True,
    },
        {
        "experiment_name": "v5_relu_bn",
        "exp_titles":"RelU+BN",
        "model_name": "standard",
        "model_kwargs": {"activation": "relu", "width": 3, "norm_type": "bn", "dilation_rate": 1},
        "upload_weights": True,
        "file_base_name": "best_model_simplet_6_fixed_model5.h5", # StandardConvNet
        "weights_filename": "v5_relu_bn_best_model.h5", # StandardConvNet
        "loss_lambdas": {"l1":1.0, "l2":0.25, "l3":0.25},
        "num_samples": 100, # -1 = use all samples; small number for quick runs
        "lr_init": 1e-3,
        "num_epochs": 50,
        "batch_size": 16,
        "preload_data": True,
    },
    {
        "experiment_name": "v6_relu_dilated_bn",
        "exp_titles":"ReLU+Dilated+BN",
        "model_name": "standard",
        "model_kwargs": {"activation": "relu", "width": 3, "norm_type": "bn", "dilation_rate": 2},
        "upload_weights": True,
        "file_base_name": "best_model_simplet_6_fixed_model5.h5", # StandardConvNet
        "weights_filename": "v6_relu_dilated_b_best_model.h5", # StandardConvNet
        "loss_lambdas": {"l1":1.0, "l2":0.25, "l3":0.25},
        "num_samples": 150, # -1 = use all samples; small number for quick runs
        "lr_init": 1e-3,
        "num_epochs": 50,
        "batch_size": 16,
        "preload_data": True,
    },

]

CFG={}
HISTORIES = {}
RUN_SUMMARY = {}
METRICS = {}

for v in VARIANTS:
    CFG.update({**BASE, **v})
    np.random.seed(CFG.get("seed", 0));tf.random.set_seed(CFG.get("seed", 0));
    model, metrics_batch, metrics_img = run_experiment(CFG)
    exp_name = v["experiment_name"]
    METRICS[exp_name] = {
        "model": model,
        "metrics_batch": metrics_batch,
        "metrics_img": metrics_img
    }

# --- Backup everything after all variants ---
backup_all_results(backup_root=BASE["backup_root"])

# # run one variant
# i=0
# v = VARIANTS[i]   # pick the variant dict
# CFG.update({**BASE, **v})
# np.random.seed(CFG.get("seed", 0));tf.random.set_seed(CFG.get("seed", 0));
# model, metrics_batch, metrics_img = run_experiment(CFG)
# exp_name = v["experiment_name"]
# METRICS[exp_name] = {
#     "model": model,
#     "metrics_batch": metrics_batch,
#     "metrics_img": metrics_img
# }

# # --- Backup everything after all variants ---
# backup_all_results(backup_root=BASE["backup_root"])

# exp_name = VARIANTS[i]["experiment_name"]
# src_path = EXP_PATHS[exp_name]["src_path"]
# checkpoint_path = EXP_PATHS[exp_name]["checkpoint_path"]

# if os.path.isfile(src_path):
#     model.load_weights(src_path)
# metrics_before_batch , metrics_before_img = evaluate_on_test(model, "", test)
# plot_metrics(metrics_before_batch)
# plot_metrics(metrics_before_img)

# plot_metrics(METRICS[i]["metrics_batch"])
# plot_metrics(METRICS[i]["metrics_img"])

# for exp_name, data in METRICS.items():
#     print(f"ğŸ” {exp_name}")
#     plot_metrics(data["metrics_batch"])
#     plot_metrics(data["metrics_img"])

# for i=0
# exp_name = VARIANTS[i]["experiment_name"]
# img_prefix = EXP_PATHS[exp_name]["img_prefix"]
# model = METRICS[exp_name]["model"]
# metrics_after_batch , metrics_after_img= evaluate_on_test(model,img_prefix,test,True)

# for exp_name in METRICS.keys():   # or list(EXP_PATHS.keys())
#     print(f"\n=== Running evaluation for {exp_name} ===")

#     img_prefix = EXP_PATHS[exp_name]["img_prefix"]
#     model = METRICS[exp_name]["model"]

#     metrics_after_batch, metrics_after_img = evaluate_on_test(
#         model, img_prefix, test, True
#     )

#     # save or update METRICS
#     METRICS[exp_name]["metrics_batch_refined"] = metrics_after_batch
#     METRICS[exp_name]["metrics_img_refined"] = metrics_after_img

# import matplotlib.pyplot as plt
# import numpy as np
# import tensorflow as tf

# def show_test_examples(test_seq, model, n_samples: int = 5):
#     """
#     ××¦×™×’ GT ××•×œ Pred ×¢×‘×•×¨ n_samples ×“×•×’×××•×ª ×¨××©×•× ×•×ª ××¡×˜ ×”-test.
#     ××¦×™×’ Intensity (GT, Pred, Diff) + Laplacian (GT, Pred) ×‘××•×ª×” ×©×•×¨×”.
#     """
#     shown = 0
#     fig, axes = plt.subplots(n_samples, 5, figsize=(20, 4*n_samples))

#     for batch_idx in range(len(test_seq)):
#         X, Y_lapl = test_seq[batch_idx]

#         # ×—×™×–×•×™
#         pred_lapl = tf.squeeze(model(X), -1)
#         pred_img  = norm_image(solve_poiss_tf(pred_lapl)).numpy()
#         gt_img    = norm_image(solve_poiss_tf(Y_lapl)).numpy()

#         for i in range(X.shape[0]):
#             if shown >= n_samples:
#                 plt.tight_layout()
#                 plt.show()
#                 return

#             # ××™× ×˜× ×¡×™×˜×™
#             gt_int   = gt_img[i, ..., 0]
#             pred_int = pred_img[i, ..., 0]
#             diff     = np.abs(gt_int - pred_int)

#             # ×œ×¤×œ×¡×™××Ÿ
#             gt_lapl   = Y_lapl[i, ..., 0] if Y_lapl.ndim == 4 else Y_lapl[i, ...]
#             pred_lapl_i = pred_lapl[i, ...]

#             # ×¦×™×•×¨
#             axes[shown, 0].imshow(gt_int, cmap="gray")
#             axes[shown, 0].set_title(f"GT Intensity #{shown}")
#             axes[shown, 0].axis("off")

#             axes[shown, 1].imshow(pred_int, cmap="gray")
#             axes[shown, 1].set_title("Predicted Intensity")
#             axes[shown, 1].axis("off")

#             im = axes[shown, 2].imshow(diff, cmap="hot")
#             axes[shown, 2].set_title("Diff (abs)")
#             axes[shown, 2].axis("off")
#             plt.colorbar(im, ax=axes[shown, 2], fraction=0.046, pad=0.04)

#             axes[shown, 3].imshow(gt_lapl, cmap="gray")
#             axes[shown, 3].set_title("GT Laplacian")
#             axes[shown, 3].axis("off")

#             axes[shown, 4].imshow(pred_lapl_i, cmap="gray")
#             axes[shown, 4].set_title("Pred Laplacian")
#             axes[shown, 4].axis("off")

#             shown += 1

#     plt.tight_layout()
#     plt.show()

import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf

def show_test_examples(test_seq, model, n_samples: int = 5, sample_indices=None):
    """
    Display GT vs Predicted outputs for selected examples from the test set.
    - If sample_indices=None â†’ show the first n_samples.
    - Otherwise â†’ show exactly the indices provided in sample_indices.
    """

    if sample_indices is None:
        sample_indices = list(range(n_samples))
    sample_indices = set(sample_indices)  # convert to set for fast lookup

    fig, axes = plt.subplots(len(sample_indices), 5, figsize=(20, 4*len(sample_indices)))
    if len(sample_indices) == 1:
        axes = np.expand_dims(axes, 0)  # keep consistent 2D array of axes

    shown = 0
    for batch_idx in range(len(test_seq)):
        X, Y_lapl = test_seq[batch_idx]

        # Model prediction (Laplacian â†’ Intensity)
        pred_lapl = tf.squeeze(model(X), -1)
        pred_img  = norm_image(solve_poiss_tf(pred_lapl)).numpy()
        gt_img    = norm_image(solve_poiss_tf(Y_lapl)).numpy()

        for i in range(X.shape[0]):
            global_idx = batch_idx * test_seq.batch_size + i
            if global_idx not in sample_indices:
                continue

            # Intensity images
            gt_int   = gt_img[i, ..., 0]
            pred_int = pred_img[i, ..., 0]
            diff     = np.abs(gt_int - pred_int)

            # Laplacian maps
            gt_lapl     = Y_lapl[i, ..., 0] if Y_lapl.ndim == 4 else Y_lapl[i, ...]
            pred_lapl_i = pred_lapl[i, ...]

            # Plot GT intensity
            row_axes = axes[shown]
            row_axes[0].imshow(gt_int, cmap="gray")
            row_axes[0].set_title(f"GT Intensity #{global_idx}")
            row_axes[0].axis("off")

            # Plot predicted intensity
            row_axes[1].imshow(pred_int, cmap="gray")
            row_axes[1].set_title("Predicted Intensity")
            row_axes[1].axis("off")

            # Plot difference heatmap
            im = row_axes[2].imshow(diff, cmap="hot")
            row_axes[2].set_title("Diff (abs)")
            row_axes[2].axis("off")
            plt.colorbar(im, ax=row_axes[2], fraction=0.046, pad=0.04)

            # Plot GT Laplacian
            row_axes[3].imshow(gt_lapl, cmap="gray")
            row_axes[3].set_title("GT Laplacian")
            row_axes[3].axis("off")

            # Plot predicted Laplacian
            row_axes[4].imshow(pred_lapl_i, cmap="gray")
            row_axes[4].set_title("Pred Laplacian")
            row_axes[4].axis("off")

            shown += 1
            if shown >= len(sample_indices):
                plt.tight_layout()
                plt.show()
                return

    plt.tight_layout()
    plt.show()

variant_lookup = {v["experiment_name"]: v.get("exp_titles", v["experiment_name"])
                  for v in VARIANTS}

for exp_name, data in METRICS.items():
    model = data["model"]
    title = variant_lookup.get(exp_name, exp_name)

    print(f"\n===== {title} =====")

    plt.figure()
    plot_metrics(data["metrics_batch"])
    plt.suptitle(f"{title} â€“ Batch metrics")
    plt.show()

    plt.figure()
    plot_metrics(data["metrics_img"])
    plt.suptitle(f"{title} â€“ Image metrics")
    plt.show()

    print(f"ğŸ‘€ Showing 2 test examples for {title}")
    # show_test_examples(test, model, n_samples=3)
    show_test_examples(test, model, sample_indices=[5, 6, 7])

# show_test_examples(test, METRICS[i]["model"], n_samples=2)

def bar_psnr(run_summary):
    import matplotlib.pyplot as plt

    labels = list(run_summary.keys())  # ×©××•×ª ×”×•×•×¨×™×× ×˜×™×
    vals   = [v["PSNRâ†‘"] for v in run_summary.values()]
    stds   = [2 * v.get("PSNR_std", 0) for v in run_summary.values()]

    plt.figure(figsize=(8,4))
    plt.bar(labels, vals, yerr=stds, capsize=5)
    plt.ylabel("PSNR (dB) â†‘")
    plt.title("PSNR by Variant (Â±2 STD)")
    plt.xticks(rotation=20); plt.tight_layout(); plt.show()

bar_psnr(RUN_SUMMARY)

import os, glob, random
import numpy as np
import matplotlib.pyplot as plt
import cv2

def show_gt_vs_variants(experiments,
                        results_dir="./results",
                        sample_indices=None,
                        n_rows=3,
                        exp_titles=None,
                        figsize_per_row=(3.5, 3.0),
                        save_path=None):
    """
    ××¦×™×™×¨ ×’×¨×™×“ ×œ×”×©×•×•××”: ×‘×›×œ ×©×•×¨×” ×“×•×’××”, ×‘×¢××•×“×•×ª: GT + ×›×œ ×”×•×•×¨×™×× ×˜×™×.
    - experiments: ×¨×©×™××ª ×©××•×ª × ×™×¡×•×™×™× (×ª×•×× ×œ×©××•×ª ×”×ª×™×§×™×•×ª ×ª×—×ª results/).
    - results_dir: ×‘×¡×™×¡ ×ª×™×§×™×™×ª ×”×ª×•×¦××•×ª.
    - sample_indices: ×¨×©×™××ª ××™× ×“×§×¡×™× (×œ××©×œ [7, 23, 41]). ×× None -> ×™×™×‘×—×¨×• ××§×¨××™×ª.
    - n_rows: ××¡×¤×¨ ×”×“×•×’×××•×ª ×œ×”×¦×’×” ×× sample_indices=None.
    - exp_titles: ×›×•×ª×¨×•×ª ×œ×¢××•×“×•×ª ×”×•×•×¨×™×× ×˜×™×; ×× None -> ×™×©×ª××© ×‘×©× ×”× ×™×¡×•×™.
    - figsize_per_row: ×’×•×“×œ ×œ×›×œ ×©×•×¨×” (×¨×•×—×‘, ×’×•×‘×”).
    - save_path: ×× ×œ× None, ×™×©××•×¨ ××ª ×”×¤×™×’×•×¨×” ×œ×§×•×‘×¥ (PNG).
    """

    assert len(experiments) >= 1, "Provide at least one experiment."

    # × ××ª×¨ ××ª ×¨×©×™××ª ×”××™× ×“×§×¡×™× ××ª×•×š ×”× ×™×¡×•×™ ×”×¨××©×•×Ÿ ×× ×œ× ×¡×•×¤×§×”
    first_exp = experiments[0]
    first_dir = os.path.join(results_dir, first_exp)
    pred_glob = sorted(glob.glob(os.path.join(first_dir, f"{first_exp}_test*_pred.png")))
    if not pred_glob:
        raise FileNotFoundError(f"No predicted images found under: {first_dir}")

    def extract_idx(path):
        # ..._testXXXX_pred.png  -> XXXX as int
        base = os.path.basename(path)
        s = base.split("_test")[-1].split("_pred.png")[0]
        return int(s)

    # Extract indices from available files in first experiment
    all_indices = [extract_idx(p) for p in pred_glob]

    if sample_indices is None:
        # instead of random, just take the first n_rows
        sample_indices = all_indices[:n_rows]

        # OR if you want fixed slice like 5th to 7th:
        # sample_indices = all_indices[4:7]   # because Python indices start at 0
    else:
        # validate indices against available
        sample_indices = [idx for idx in sample_indices if idx in all_indices]
        if not sample_indices:
            raise ValueError("None of the provided sample_indices exist in the results folder.")

    # ×›×•×ª×¨×•×ª ×œ×¢××•×“×•×ª
    if exp_titles is None or len(exp_titles) != len(experiments):
        exp_titles = experiments

    n_cols = 1 + len(experiments)  # GT + ×›×œ ×”×•×•×¨×™×× ×˜×™×
    fig = plt.figure(figsize=(figsize_per_row[0]*n_cols, figsize_per_row[1]*len(sample_indices)))

    # ×¤×•× ×§×¦×™×™×ª ×¢×–×¨ ×œ×˜×¢×™× ×” ×›-gray
    def load_gray(path):
        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
        if img is None:
            raise FileNotFoundError(f"Missing image: {path}")
        return img

    # ×¦×™×•×¨
    for r, idx in enumerate(sample_indices):
        # GT: × ×œ×§×— ××ª×•×š ×”× ×™×¡×•×™ ×”×¨××©×•×Ÿ (×–×”×•×ª ×œ×›×œ ×”×•×•×¨×™×× ×˜×™×)
        gt_path = os.path.join(results_dir, first_exp, f"{first_exp}_test{idx:04d}_gt.png")
        gt_img  = load_gray(gt_path)
        ax = plt.subplot(len(sample_indices), n_cols, r*n_cols + 1)
        ax.imshow(gt_img, cmap="gray"); ax.axis("off")
        if r == 0: ax.set_title("GT", fontsize=10)

        # ×•×•×¨×™×× ×˜×™×
        for c, exp in enumerate(experiments):
            pred_path = os.path.join(results_dir, exp, f"{exp}_test{idx:04d}_pred.png")
            pred_img  = load_gray(pred_path)
            ax = plt.subplot(len(sample_indices), n_cols, r*n_cols + (c+2))
            ax.imshow(pred_img, cmap="gray"); ax.axis("off")
            if r == 0: ax.set_title(exp_titles[c], fontsize=10)

    plt.tight_layout()
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches="tight")
        print(f"Saved figure â†’ {save_path}")
    plt.show()

experiments = list(HISTORIES.keys())

variant_lookup = {v["experiment_name"]: v.get("exp_titles", v["experiment_name"])
                  for v in VARIANTS}
titles = [variant_lookup[name] for name in HISTORIES.keys()]


# 3 random examples
# show_gt_vs_variants(experiments, results_dir="./results", n_rows=3, save_path="./results/comparison_grid.png")

# specific examples (by testXXXX index):
show_gt_vs_variants(experiments, results_dir="./results",
                    sample_indices=[10, 6, 7],
                    exp_titles=titles,
                    save_path="./results/comparison_grid.png")

import pandas as pd
import matplotlib.pyplot as plt

def summarize_metrics(METRICS, HISTORIES):

    rows = []

    for exp, data in METRICS.items():
        df_img = data["metrics_img"]  # DataFrame ×¢× ×¢××•×“×•×ª PSNR/SSIM/MSE ×œ×›×œ ×ª××•× ×”
        psnr_mean = df_img["PSNR"].mean()
        ssim_mean = df_img["SSIM"].mean()
        mse_mean  = df_img["MSE"].mean()

        model = data.get("model", None)
        params = model.count_params() if model is not None else None

        rows.append({
            "Experiment": exp,
            "Params": f"{params:,}" if params is not None else "n/a",
            "PSNR â†‘": round(psnr_mean, 3),
            "SSIM â†‘": round(ssim_mean, 3),
            "MSE â†“": round(mse_mean, 6),
        })

    summary_df = pd.DataFrame(rows)

    # ===== ×˜×‘×œ×” =====
    print("ğŸ“Š Summary Table:")
    display(summary_df)

    return summary_df

summary_df = summarize_metrics(METRICS, HISTORIES )

# import pandas as pd

# def summarize_metrics(METRICS, HISTORIES, VARIANTS):

#     variant_lookup = {v["experiment_name"]: v.get("exp_titles", v["experiment_name"])
#                       for v in VARIANTS}
#     titles = [variant_lookup[name] for name in HISTORIES.keys()]
#     experiments = list(HISTORIES.keys())


#     rows = []
#     i=0
#     for exp, data in METRICS.items():
#         df_img = data["metrics_img"]  # DataFrame ×¢× ×¢××•×“×•×ª PSNR/SSIM/MSE ×œ×›×œ ×ª××•× ×”
#         psnr_mean = df_img["PSNR"].mean()
#         ssim_mean = df_img["SSIM"].mean()
#         mse_mean  = df_img["MSE"].mean()

#         model = data.get("model", None)
#         params = model.count_params() if model is not None else None

#         exp_title =  titles[i]
#         exp_title =  experiments[i]

#         rows.append({
#             "Variant": exp_title,
#             "Params": f"{params:,}" if params is not None else "n/a",
#             "PSNR â†‘": round(psnr_mean, 3),
#             "SSIM â†‘": round(ssim_mean, 4),
#             "MSE â†“": round(mse_mean, 6),
#         })
#         i=+1
#     summary_df = pd.DataFrame(rows)

#     print("ğŸ“Š Summary Table:")
#     display(summary_df)

#     return summary_df

# summary_df = summarize_metrics(METRICS, HISTORIES, VARIANTS )

import pandas as pd
import matplotlib.pyplot as plt

def summarize_metrics_cv(METRICS, HISTORIES):

    rows = []

    for exp, data in METRICS.items():
        df_img = data["metrics_img"]  # DataFrame ×¢× ×¢××•×“×•×ª PSNR/SSIM/MSE ×œ×›×œ ×ª××•× ×”
        psnr_mean = df_img["PSNR"].mean()
        ssim_mean = df_img["SSIM"].mean()
        mse_mean  = df_img["MSE"].mean()
        psnr_std = df_img["PSNR"].std()
        ssim_std = df_img["SSIM"].std()
        mse_std  = df_img["MSE"].std()

        model = data.get("model", None)
        params = model.count_params() if model is not None else None

        rows.append({
            "Experiment": exp,
            "Params": f"{params:,}" if params is not None else "n/a",
            "PSNR CV": round(psnr_std/psnr_mean, 3),
            "SSIM CV": round(ssim_std/ssim_mean, 3),
            "MSE CV": round(mse_std/mse_mean, 6),
        })

    summary_df = pd.DataFrame(rows)

    # ===== ×˜×‘×œ×” =====
    print("ğŸ“Š Summary Table:")
    display(summary_df)

    return summary_df

summary_df = summarize_metrics_cv(METRICS, HISTORIES )

import pandas as pd
import matplotlib.pyplot as plt

def summarize_loss(METRICS, HISTORIES):


    variant_lookup = {v["experiment_name"]: v.get("exp_titles", v["experiment_name"])
                      for v in VARIANTS}
    titles = [variant_lookup[name] for name in HISTORIES.keys()]
    experiments = list(HISTORIES.keys())

    # --- ×’×¨×£ LOSS ---
    i=0
    plt.figure(figsize=(8,5))
    for exp, hist in HISTORIES.items():
        if "loss" in hist:
            plt.plot(hist["loss"], label=f"{exp} - loss")
        if "val_loss" in hist:
            # plt.plot(hist["val_loss"], linestyle="--", label=f"{titles[i]} - val_loss")
            plt.plot(hist["val_loss"], linestyle="--", label=f"{exp} - val_loss")
        i=+1

    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.title("Training Loss Curves")
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

    return

summarize_loss(METRICS, HISTORIES)

# def mish(x):
#     return x * tf.math.tanh(tf.math.softplus(x))

# import h5py, tensorflow as tf, numpy as np

# # 1) ×‘×•× ×” ××ª ×”××•×“×œ ×‘×“×™×•×§ ×¢× ××•×ª× ×¤×¨××˜×¨×™× (×©×™××™ ×œ×‘ ×œ-width)
# # model = StandardConvNet(activation="relu", width=3, name="StandardConvNet")
# # _ = model(tf.random.uniform([1, 90, 120, 6]))  # build vars
# # model.summary()

# # model = StandardConvNet(activation="mish", width=3, name="StandardConvNet")
# # _ = model(tf.random.uniform([1, 90, 120, 6]))  # build vars
# # model.summary()

# model = StandardConvNetDilatedBN(activation="mish", width=3, dilation_rate=2, name="StandardConvNetDilatedBN")
# _ = model(tf.random.uniform([1, 90, 120, 6]))  # build vars
# model.summary()


# # 2) ××“×¤×™×¡ ××ª ×©×/×¦×•×¨×ª ×”××©×§×•×œ×•×ª ×©×”××•×“×œ ××¦×¤×” ×œ×”×Ÿ
# print("\n=== Model weights (expected) ===")
# for w in model.weights:
#     print(f"{w.name:40s} <- {tuple(w.shape)}")

# # 3) ×¡×•×¨×§ ××ª ×§×•×‘×¥ ×”-H5 ×•××“×¤×™×¡ ×˜× ×¡×•×¨×™× ×‘×¤× ×™×
# h5_path = "/content/drive/MyDrive/OpenU/Hadar cohen - Nbel-lab/Seminar in cs 2025/exercise/CVPR-2021-W/best_model_simplet_6_fixed_model5.h5"
# def scan_h5(h5_path):
#     with h5py.File(h5_path, "r") as f:
#         print("\n=== H5 top-level groups ===", list(f.keys()))
#         names = []
#         def visit(n, o):
#             if isinstance(o, h5py.Dataset):
#                 names.append((n, o.shape))
#         f.visititems(visit)
#     for n, shp in names:
#         print(f"{n:70s} -> {shp}")
#     print(f"Total tensors in file: {len(names)}")

# scan_h5(h5_path)

# # 4) ×× ×¡×” ×˜×¢×™× ×” ××œ××” ×•××– ×—×œ×§×™×ªâ€”×¢× ×œ×•×’ ×‘×¨×•×¨
# print("\n=== Strict load ===")
# try:
#     model.load_weights(h5_path)
#     print("âœ… strict load ok")
# except Exception as e:
#     print("âŒ strict load failed:", e)

# print("\n=== Partial load (by_name, skip_mismatch) ===")
# try:
#     model.load_weights(h5_path, by_name=True, skip_mismatch=True)
#     print("âœ… partial load ok (skipped mismatches)")
# except Exception as e:
#     print("âŒ partial load failed:", e)

import matplotlib.pyplot as plt
import os

def summarize_loss(HISTORIES, VARIANTS, results_dir="./results"):
    # Make sure the results directory exists
    os.makedirs(results_dir, exist_ok=True)

    # Map experiment_name â†’ nice title
    variant_lookup = {v["experiment_name"]: v.get("exp_titles", v["experiment_name"])
                      for v in VARIANTS}

    for exp, hist in HISTORIES.items():
        title = variant_lookup.get(exp, exp)

        plt.figure(figsize=(8, 5))
        if "loss" in hist:
            plt.plot(hist["loss"], label="Train Loss")
        if "val_loss" in hist:
            plt.plot(hist["val_loss"], linestyle="--", label="Val Loss")

        plt.xlabel("Epoch")
        plt.ylabel("Loss")
        plt.title(f"Training Loss â€“ {title}")
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()

        # Save figure to results_dir
        save_path = os.path.join(results_dir, f"{exp}_loss_curve.png")
        plt.savefig(save_path, dpi=150)
        print(f"ğŸ’¾ Saved loss curve for {title} â†’ {save_path}")

        plt.show()

summarize_loss(HISTORIES, VARIANTS, results_dir="./results")

# --- Backup everything after all variants ---
backup_all_results(backup_root=BASE["backup_root"])